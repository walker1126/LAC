<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
    	<meta name="description" content="LAC - Latent Action Composition for Skeleton-based Action Segmentation">

    	<title>LAC - Latent Action Composition for Skeleton-based Action Segmentation</title>
		
    	<link href="css/bootstrap.min.css" rel="stylesheet">
    	<link href="css/style.css" rel="stylesheet">
    </head>

    <body>

	<div class="container">
      <div class="header">
        <h2><center> 
		LAC - Latent Action Composition for Skeleton-based Action Segmentation
		<br/> (ICCV'2023)</center></h2>
		<h3><center></center></h3>
		<h4> <center> <a href="https://walker1126.github.io" class="text-info"> Di Yang </a>  &nbsp&nbsp&nbsp&nbsp  <a href="http://www-sop.inria.fr/members/Yaohui.Wang" class="text-info"> Yaohui Wang </a>  &nbsp&nbsp&nbsp&nbsp <a href="http://antitza.com" class="text-info">Antitza Dantcheva</a> &nbsp&nbsp&nbsp&nbsp <a href="https://fusionk.github.io/quankong/" class="text-info">Quan Kong</a> &nbsp&nbsp&nbsp&nbsp <a href="https://www.linkedin.com/in/lorenzo-garattoni/" class="text-info">Lorenzo Garattoni</a> &nbsp&nbsp&nbsp&nbsp <a href="https://iridia.ulb.ac.be/~gfrancesca/Gianpiero_Francesca/Home.html" class="text-info">Gianpiero Francesca </a> &nbsp&nbsp&nbsp&nbsp <a href="http://www-sop.inria.fr/members/Francois.Bremond/" class="text-info">François Brémond</a> </center> </h4>
		<h4> <center>Inria, &nbsp&nbsp Université Côte d&#39Azur, &nbsp&nbsp Toyota Motor Europe, &nbsp&nbsp Woven by Toyota</center> </h4>
	  </div>

	<div class="row">
    <hr>
    <h2><center>Abstract</center></h2>
    <h4> In this work, we propose Latent Action Composition (LAC), a novel self-supervised framework aiming at learning from synthesized composable motions for skeleton-based action segmentation. LAC is composed of a novel generation module towards synthesizing new sequences. Specifically, we design a linear latent space in the generator to represent primitive motion. New composed motions can be synthesized by simply performing arithmetic operations on latent representations of multiple input skeleton sequences. LAC leverages such synthesized sequences, which have large diversity and complexity, for learning visual representations of skeletons in both sequence and frame spaces via contrastive learning. The resulting visual encoder has a high expressive power and can be effectively transferred onto action segmentation tasks by end-to-end fine-tuning without the need for additional temporal models. We conduct a study focusing on transfer-learning and we show that representations learned from pre-trained LAC outperform the state-of-the-art by a large margin on TSU, Charades, PKU-MMD datasets. 
    </h4>
	
   <center>
   	<video width="1120" height="630" autoplay="autoplay" loop="loop" muted="muted" controls>
		<source src="imgs/video-5050.mp4" type="video/mp4">
	</video>
	
	</center>
	</div>	
	
    <!--
<h3><a href="https://arxiv.org/pdf/2107.08580" class="text-info">[Paper]</a> &nbsp&nbsp&nbsp&nbsp <a href="https://github.com/YangDi666/UNIK" class="text-info">[Code]</a> &nbsp&nbsp&nbsp&nbsp <a href="https://github.com/YangDi666/UNIK" class="text-info">[Posetics Dataset]</a>
 
    <div class="row">
    <hr>
    <h2><center>Results</center></h2>
	 
	<figure>
		<center>
		<img src="imgs/curve.jpg" title="" style="max-width:100%;vertical-align:top"/>
		
		</center>
		
		<figcaption><b>UNIK.</b> 
		
	  	
		</figure>	
	</div>
	-->
	<hr>
	</div>
    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    </body>
</html>
